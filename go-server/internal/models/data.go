package models

// Models contains all AI model entries in the registry.
// Data verified against official docs as of February 2026.
var Models = map[string]Model{
	// ─── OpenAI: Current ───────────────────────────────────────────────
	"gpt-5.2": {
		ID:              "gpt-5.2",
		DisplayName:     "GPT-5.2",
		Provider:        "OpenAI",
		ContextWindow:   400_000,
		MaxOutputTokens: 128_000,
		Vision:          true,
		Reasoning:       true,
		PricingInput:    1.75,
		PricingOutput:   14.00,
		KnowledgeCutoff: "2025-08",
		ReleaseDate:     "2025-12",
		Status:          "current",
		Notes:           "Latest flagship GPT model with thinking, 400K context",
	},
	"gpt-5.2-codex": {
		ID:              "gpt-5.2-codex",
		DisplayName:     "GPT-5.2 Codex",
		Provider:        "OpenAI",
		ContextWindow:   400_000,
		MaxOutputTokens: 128_000,
		Vision:          true,
		Reasoning:       true,
		PricingInput:    1.75,
		PricingOutput:   14.00,
		KnowledgeCutoff: "2025-08",
		ReleaseDate:     "2026-01",
		Status:          "deprecated",
		Notes:           "Optimized for agentic coding, strong long-horizon task completion",
	},
	"gpt-5.2-pro": {
		ID:              "gpt-5.2-pro",
		DisplayName:     "GPT-5.2 Pro",
		Provider:        "OpenAI",
		ContextWindow:   400_000,
		MaxOutputTokens: 128_000,
		Vision:          true,
		Reasoning:       true,
		PricingInput:    21.00,
		PricingOutput:   168.00,
		KnowledgeCutoff: "2025-08",
		ReleaseDate:     "2025-12",
		Status:          "current",
		Notes:           "Pro variant with extended reasoning, Responses API only",
	},
	"gpt-5.1": {
		ID:              "gpt-5.1",
		DisplayName:     "GPT-5.1",
		Provider:        "OpenAI",
		ContextWindow:   400_000,
		MaxOutputTokens: 128_000,
		Vision:          true,
		Reasoning:       true,
		PricingInput:    1.25,
		PricingOutput:   10.00,
		KnowledgeCutoff: "2024-09",
		ReleaseDate:     "2025-11",
		Status:          "current",
		Notes:           "Flagship for coding and agentic tasks",
	},
	"gpt-5.1-codex": {
		ID:              "gpt-5.1-codex",
		DisplayName:     "GPT-5.1 Codex",
		Provider:        "OpenAI",
		ContextWindow:   400_000,
		MaxOutputTokens: 128_000,
		Vision:          true,
		Reasoning:       true,
		PricingInput:    1.25,
		PricingOutput:   10.00,
		KnowledgeCutoff: "2024-09",
		ReleaseDate:     "2025-11",
		Status:          "current",
		Notes:           "Agentic coding model, optimized for long-horizon code tasks",
	},
	"gpt-5.1-codex-mini": {
		ID:              "gpt-5.1-codex-mini",
		DisplayName:     "GPT-5.1 Codex Mini",
		Provider:        "OpenAI",
		ContextWindow:   400_000,
		MaxOutputTokens: 128_000,
		Vision:          true,
		Reasoning:       true,
		PricingInput:    0.25,
		PricingOutput:   2.00,
		KnowledgeCutoff: "2024-09",
		ReleaseDate:     "2025-11",
		Status:          "deprecated",
		Notes:           "Cost-efficient coding model for quick completions",
	},
	"gpt-5": {
		ID:              "gpt-5",
		DisplayName:     "GPT-5",
		Provider:        "OpenAI",
		ContextWindow:   400_000,
		MaxOutputTokens: 128_000,
		Vision:          true,
		Reasoning:       true,
		PricingInput:    1.25,
		PricingOutput:   10.00,
		KnowledgeCutoff: "2024-10",
		ReleaseDate:     "2025-08",
		Status:          "current",
		Notes:           "400K context, flagship with configurable reasoning",
	},
	"gpt-5-mini": {
		ID:              "gpt-5-mini",
		DisplayName:     "GPT-5 Mini",
		Provider:        "OpenAI",
		ContextWindow:   400_000,
		MaxOutputTokens: 128_000,
		Vision:          true,
		Reasoning:       true,
		PricingInput:    0.25,
		PricingOutput:   2.00,
		KnowledgeCutoff: "2024-05",
		ReleaseDate:     "2025-09",
		Status:          "current",
		Notes:           "Cost-efficient GPT-5 variant, 400K context, reasoning support",
	},
	"gpt-5-nano": {
		ID:              "gpt-5-nano",
		DisplayName:     "GPT-5 Nano",
		Provider:        "OpenAI",
		ContextWindow:   400_000,
		MaxOutputTokens: 128_000,
		Vision:          true,
		Reasoning:       true,
		PricingInput:    0.05,
		PricingOutput:   0.40,
		KnowledgeCutoff: "2024-05",
		ReleaseDate:     "2025-08",
		Status:          "current",
		Notes:           "Fastest and cheapest GPT-5 variant, great for summarization/classification",
	},
	"gpt-4.1-mini": {
		ID:              "gpt-4.1-mini",
		DisplayName:     "GPT-4.1 Mini",
		Provider:        "OpenAI",
		ContextWindow:   1_047_576,
		MaxOutputTokens: 32_768,
		Vision:          true,
		Reasoning:       false,
		PricingInput:    0.40,
		PricingOutput:   1.60,
		KnowledgeCutoff: "2024-06",
		ReleaseDate:     "2025-04",
		Status:          "current",
		Notes:           "1M context, cost-efficient",
	},
	"gpt-4.1-nano": {
		ID:              "gpt-4.1-nano",
		DisplayName:     "GPT-4.1 Nano",
		Provider:        "OpenAI",
		ContextWindow:   1_047_576,
		MaxOutputTokens: 32_768,
		Vision:          true,
		Reasoning:       false,
		PricingInput:    0.10,
		PricingOutput:   0.40,
		KnowledgeCutoff: "2024-06",
		ReleaseDate:     "2025-04",
		Status:          "current",
		Notes:           "Fastest and cheapest GPT-4.1 variant",
	},
	"o3": {
		ID:              "o3",
		DisplayName:     "o3",
		Provider:        "OpenAI",
		ContextWindow:   200_000,
		MaxOutputTokens: 100_000,
		Vision:          true,
		Reasoning:       true,
		PricingInput:    2.00,
		PricingOutput:   8.00,
		KnowledgeCutoff: "2024-06",
		ReleaseDate:     "2025-04",
		Status:          "current",
		Notes:           "Flagship reasoning model, strong at math/science/coding",
	},
	"o3-pro": {
		ID:              "o3-pro",
		DisplayName:     "o3 Pro",
		Provider:        "OpenAI",
		ContextWindow:   200_000,
		MaxOutputTokens: 100_000,
		Vision:          true,
		Reasoning:       true,
		PricingInput:    20.00,
		PricingOutput:   80.00,
		KnowledgeCutoff: "2024-06",
		ReleaseDate:     "2025-06",
		Status:          "deprecated",
		Notes:           "Extended thinking version of o3, available via Responses API only",
	},
	"o4-mini": {
		ID:              "o4-mini",
		DisplayName:     "o4-mini",
		Provider:        "OpenAI",
		ContextWindow:   200_000,
		MaxOutputTokens: 100_000,
		Vision:          true,
		Reasoning:       true,
		PricingInput:    1.10,
		PricingOutput:   4.40,
		KnowledgeCutoff: "2024-06",
		ReleaseDate:     "2025-04",
		Status:          "current",
		Notes:           "Cost-efficient reasoning model",
	},
	"o3-deep-research": {
		ID:              "o3-deep-research",
		DisplayName:     "o3 Deep Research",
		Provider:        "OpenAI",
		ContextWindow:   200_000,
		MaxOutputTokens: 100_000,
		Vision:          true,
		Reasoning:       true,
		PricingInput:    10.00,
		PricingOutput:   40.00,
		KnowledgeCutoff: "2024-06",
		ReleaseDate:     "2025-11",
		Status:          "deprecated",
		Notes:           "Deep research model, analyzes hundreds of sources, requires Responses API",
	},
	"o3-mini": {
		ID:              "o3-mini",
		DisplayName:     "o3-mini",
		Provider:        "OpenAI",
		ContextWindow:   200_000,
		MaxOutputTokens: 100_000,
		Vision:          false,
		Reasoning:       true,
		PricingInput:    1.10,
		PricingOutput:   4.40,
		KnowledgeCutoff: "2023-10",
		ReleaseDate:     "2025-01",
		Status:          "legacy",
		Notes:           "Predecessor to o4-mini, superseded by o4-mini",
	},
	// ─── OpenAI: Legacy/Deprecated ─────────────────────────────────────
	"gpt-4.1": {
		ID:              "gpt-4.1",
		DisplayName:     "GPT-4.1",
		Provider:        "OpenAI",
		ContextWindow:   1_047_576,
		MaxOutputTokens: 32_768,
		Vision:          true,
		Reasoning:       false,
		PricingInput:    2.00,
		PricingOutput:   8.00,
		KnowledgeCutoff: "2024-06",
		ReleaseDate:     "2025-04",
		Status:          "deprecated",
		Notes:           "1M context window, strong coding. Retiring from ChatGPT Feb 13, 2026. Superseded by GPT-5 series",
	},
	"gpt-4o": {
		ID:              "gpt-4o",
		DisplayName:     "GPT-4o",
		Provider:        "OpenAI",
		ContextWindow:   128_000,
		MaxOutputTokens: 16_384,
		Vision:          true,
		Reasoning:       false,
		PricingInput:    2.50,
		PricingOutput:   10.00,
		KnowledgeCutoff: "2023-10",
		ReleaseDate:     "2024-05",
		Status:          "deprecated",
		Notes:           "Retiring Feb 13, 2026. Superseded by GPT-5 series",
	},
	"gpt-4o-mini": {
		ID:              "gpt-4o-mini",
		DisplayName:     "GPT-4o Mini",
		Provider:        "OpenAI",
		ContextWindow:   128_000,
		MaxOutputTokens: 16_384,
		Vision:          true,
		Reasoning:       false,
		PricingInput:    0.15,
		PricingOutput:   0.60,
		KnowledgeCutoff: "2023-10",
		ReleaseDate:     "2024-07",
		Status:          "deprecated",
		Notes:           "Superseded by GPT-4.1 Mini/Nano",
	},
	// ─── Anthropic: Current ────────────────────────────────────────────
	"claude-opus-4-6": {
		ID:              "claude-opus-4-6",
		DisplayName:     "Claude Opus 4.6",
		Provider:        "Anthropic",
		ContextWindow:   200_000,
		MaxOutputTokens: 128_000,
		Vision:          true,
		Reasoning:       true,
		PricingInput:    5.00,
		PricingOutput:   25.00,
		KnowledgeCutoff: "2025-05",
		ReleaseDate:     "2026-02",
		Status:          "current",
		Notes:           "Most capable Anthropic model, extended thinking, adaptive thinking. 1M token context window available in beta (requires context-1m-2025-08-07 header, tier 4+ orgs). Premium pricing >200K: $10/$37.50 per 1M tokens.",
	},
	"claude-sonnet-4-5-20250929": {
		ID:              "claude-sonnet-4-5-20250929",
		DisplayName:     "Claude Sonnet 4.5",
		Provider:        "Anthropic",
		ContextWindow:   200_000,
		MaxOutputTokens: 64_000,
		Vision:          true,
		Reasoning:       true,
		PricingInput:    3.00,
		PricingOutput:   15.00,
		KnowledgeCutoff: "2025-01",
		ReleaseDate:     "2025-09",
		Status:          "current",
		Notes:           "Best speed/intelligence balance, extended thinking. Alias: claude-sonnet-4-5",
	},
	"claude-haiku-4-5-20251001": {
		ID:              "claude-haiku-4-5-20251001",
		DisplayName:     "Claude Haiku 4.5",
		Provider:        "Anthropic",
		ContextWindow:   200_000,
		MaxOutputTokens: 64_000,
		Vision:          true,
		Reasoning:       true,
		PricingInput:    1.00,
		PricingOutput:   5.00,
		KnowledgeCutoff: "2025-02",
		ReleaseDate:     "2025-10",
		Status:          "current",
		Notes:           "Fastest Anthropic model, extended thinking. Alias: claude-haiku-4-5",
	},
	// ─── Anthropic: Legacy/Deprecated ──────────────────────────────────
	"claude-opus-4-5": {
		ID:              "claude-opus-4-5",
		DisplayName:     "Claude Opus 4.5",
		Provider:        "Anthropic",
		ContextWindow:   200_000,
		MaxOutputTokens: 64_000,
		Vision:          true,
		Reasoning:       true,
		PricingInput:    5.00,
		PricingOutput:   25.00,
		KnowledgeCutoff: "2025-05",
		ReleaseDate:     "2025-11",
		Status:          "legacy",
		Notes:           "Superseded by Claude Opus 4.6. Full ID: claude-opus-4-5-20251101",
	},
	"claude-opus-4-1": {
		ID:              "claude-opus-4-1",
		DisplayName:     "Claude Opus 4.1",
		Provider:        "Anthropic",
		ContextWindow:   200_000,
		MaxOutputTokens: 32_000,
		Vision:          true,
		Reasoning:       true,
		PricingInput:    15.00,
		PricingOutput:   75.00,
		KnowledgeCutoff: "2025-01",
		ReleaseDate:     "2025-08",
		Status:          "legacy",
		Notes:           "Superseded by Claude Opus 4.5/4.6. Full ID: claude-opus-4-1-20250805",
	},
	"claude-sonnet-4-0": {
		ID:              "claude-sonnet-4-0",
		DisplayName:     "Claude Sonnet 4.0",
		Provider:        "Anthropic",
		ContextWindow:   200_000,
		MaxOutputTokens: 64_000,
		Vision:          true,
		Reasoning:       true,
		PricingInput:    3.00,
		PricingOutput:   15.00,
		KnowledgeCutoff: "2025-01",
		ReleaseDate:     "2025-05",
		Status:          "legacy",
		Notes:           "Superseded by Claude Sonnet 4.5. Full ID: claude-sonnet-4-20250514",
	},
	"claude-3-7-sonnet-20250219": {
		ID:              "claude-3-7-sonnet-20250219",
		DisplayName:     "Claude 3.7 Sonnet",
		Provider:        "Anthropic",
		ContextWindow:   200_000,
		MaxOutputTokens: 64_000,
		Vision:          true,
		Reasoning:       true,
		PricingInput:    3.00,
		PricingOutput:   15.00,
		KnowledgeCutoff: "2024-10",
		ReleaseDate:     "2025-02",
		Status:          "deprecated",
		Notes:           "Superseded by Claude Sonnet 4.x. Alias: claude-3-7-sonnet-latest",
	},
	"claude-opus-4-0": {
		ID:              "claude-opus-4-0",
		DisplayName:     "Claude Opus 4.0",
		Provider:        "Anthropic",
		ContextWindow:   200_000,
		MaxOutputTokens: 32_000,
		Vision:          true,
		Reasoning:       true,
		PricingInput:    15.00,
		PricingOutput:   75.00,
		KnowledgeCutoff: "2025-01",
		ReleaseDate:     "2025-05",
		Status:          "legacy",
		Notes:           "Superseded by Claude Opus 4.5/4.6. Full ID: claude-opus-4-20250514",
	},
	// ─── Google: Current ───────────────────────────────────────────────
	"gemini-3-pro-preview": {
		ID:              "gemini-3-pro-preview",
		DisplayName:     "Gemini 3 Pro (Preview)",
		Provider:        "Google",
		ContextWindow:   1_048_576,
		MaxOutputTokens: 65_536,
		Vision:          true,
		Reasoning:       true,
		PricingInput:    2.00,
		PricingOutput:   12.00,
		KnowledgeCutoff: "2025-09",
		ReleaseDate:     "2025-11",
		Status:          "current",
		Notes:           "Latest Gemini flagship, 1M context, preview",
	},
	"gemini-3-pro-image-preview": {
		ID:              "gemini-3-pro-image-preview",
		DisplayName:     "Gemini 3 Pro Image (Preview)",
		Provider:        "Google",
		ContextWindow:   65_536,
		MaxOutputTokens: 32_768,
		Vision:          true,
		Reasoning:       true,
		PricingInput:    2.00,
		PricingOutput:   120.00,
		KnowledgeCutoff: "2025-01",
		ReleaseDate:     "2025-11",
		Status:          "deprecated",
		Notes:           "Image generation and understanding model, output pricing is for image tokens",
	},
	"gemini-3-flash-preview": {
		ID:              "gemini-3-flash-preview",
		DisplayName:     "Gemini 3 Flash (Preview)",
		Provider:        "Google",
		ContextWindow:   1_048_576,
		MaxOutputTokens: 65_536,
		Vision:          true,
		Reasoning:       true,
		PricingInput:    0.50,
		PricingOutput:   3.00,
		KnowledgeCutoff: "2025-09",
		ReleaseDate:     "2025-12",
		Status:          "current",
		Notes:           "Fast Gemini 3 variant, preview",
	},
	"gemini-2.5-pro": {
		ID:              "gemini-2.5-pro",
		DisplayName:     "Gemini 2.5 Pro",
		Provider:        "Google",
		ContextWindow:   1_048_576,
		MaxOutputTokens: 65_536,
		Vision:          true,
		Reasoning:       true,
		PricingInput:    1.25,
		PricingOutput:   10.00,
		KnowledgeCutoff: "2025-03",
		ReleaseDate:     "2025-03",
		Status:          "current",
		Notes:           "Thinking model, 1M context",
	},
	"gemini-2.5-flash": {
		ID:              "gemini-2.5-flash",
		DisplayName:     "Gemini 2.5 Flash",
		Provider:        "Google",
		ContextWindow:   1_048_576,
		MaxOutputTokens: 65_536,
		Vision:          true,
		Reasoning:       true,
		PricingInput:    0.30,
		PricingOutput:   2.50,
		KnowledgeCutoff: "2025-03",
		ReleaseDate:     "2025-05",
		Status:          "current",
		Notes:           "Fast and cost-efficient with thinking",
	},
	"gemini-2.5-flash-lite": {
		ID:              "gemini-2.5-flash-lite",
		DisplayName:     "Gemini 2.5 Flash Lite",
		Provider:        "Google",
		ContextWindow:   1_048_576,
		MaxOutputTokens: 65_536,
		Vision:          true,
		Reasoning:       false,
		PricingInput:    0.10,
		PricingOutput:   0.40,
		KnowledgeCutoff: "2025-03",
		ReleaseDate:     "2025-06",
		Status:          "deprecated",
		Notes:           "Cheapest Gemini option, no thinking mode",
	},
	// ─── Google: Legacy/Deprecated ─────────────────────────────────────
	"gemini-2.0-flash-lite": {
		ID:              "gemini-2.0-flash-lite",
		DisplayName:     "Gemini 2.0 Flash Lite",
		Provider:        "Google",
		ContextWindow:   1_048_576,
		MaxOutputTokens: 8_192,
		Vision:          true,
		Reasoning:       false,
		PricingInput:    0.075,
		PricingOutput:   0.30,
		KnowledgeCutoff: "2024-08",
		ReleaseDate:     "2025-02",
		Status:          "deprecated",
		Notes:           "Retiring March 31, 2026. Use Gemini 2.5 Flash Lite instead",
	},
	"gemini-2.0-flash": {
		ID:              "gemini-2.0-flash",
		DisplayName:     "Gemini 2.0 Flash",
		Provider:        "Google",
		ContextWindow:   1_048_576,
		MaxOutputTokens: 8_192,
		Vision:          true,
		Reasoning:       false,
		PricingInput:    0.10,
		PricingOutput:   0.40,
		KnowledgeCutoff: "2024-08",
		ReleaseDate:     "2025-02",
		Status:          "deprecated",
		Notes:           "Retiring March 2026, use Gemini 2.5 Flash instead",
	},
	// ─── xAI: Current ──────────────────────────────────────────────────
	"grok-4": {
		ID:              "grok-4",
		DisplayName:     "Grok 4",
		Provider:        "xAI",
		ContextWindow:   256_000,
		MaxOutputTokens: 131_072,
		Vision:          true,
		Reasoning:       true,
		PricingInput:    3.00,
		PricingOutput:   15.00,
		KnowledgeCutoff: "2024-11",
		ReleaseDate:     "2025-07",
		Status:          "current",
		Notes:           "xAI flagship reasoning model",
	},
	"grok-4.1": {
		ID:              "grok-4.1",
		DisplayName:     "Grok 4.1",
		Provider:        "xAI",
		ContextWindow:   2_000_000,
		MaxOutputTokens: 131_072,
		Vision:          false,
		Reasoning:       true,
		PricingInput:    3.00,
		PricingOutput:   15.00,
		KnowledgeCutoff: "2024-11",
		ReleaseDate:     "2025-11",
		Status:          "deprecated",
		Notes:           "#1 LMArena Text Arena (1483 Elo), 2M context, thinking/reasoning, text-only",
	},
	"grok-4.1-fast": {
		ID:              "grok-4.1-fast",
		DisplayName:     "Grok 4.1 Fast",
		Provider:        "xAI",
		ContextWindow:   2_000_000,
		MaxOutputTokens: 8_192,
		Vision:          true,
		Reasoning:       true,
		PricingInput:    0.20,
		PricingOutput:   0.50,
		KnowledgeCutoff: "2024-11",
		ReleaseDate:     "2025-11",
		Status:          "current",
		Notes:           "2M context, fast tool-calling model, low hallucination",
	},
	"grok-4-fast": {
		ID:              "grok-4-fast",
		DisplayName:     "Grok 4 Fast",
		Provider:        "xAI",
		ContextWindow:   2_000_000,
		MaxOutputTokens: 30_000,
		Vision:          true,
		Reasoning:       true,
		PricingInput:    0.20,
		PricingOutput:   0.50,
		KnowledgeCutoff: "2024-11",
		ReleaseDate:     "2025-09",
		Status:          "current",
		Notes:           "2M context, reasoning and non-reasoning modes, 40% fewer thinking tokens vs Grok 4",
	},
	"grok-code-fast-1": {
		ID:              "grok-code-fast-1",
		DisplayName:     "Grok Code Fast 1",
		Provider:        "xAI",
		ContextWindow:   256_000,
		MaxOutputTokens: 65_536,
		Vision:          false,
		Reasoning:       true,
		PricingInput:    0.20,
		PricingOutput:   1.50,
		KnowledgeCutoff: "2024-11",
		ReleaseDate:     "2025-08",
		Status:          "current",
		Notes:           "Specialized agentic coding model, SWE-Bench 70.8%",
	},
	// ─── xAI: Legacy ───────────────────────────────────────────────────
	"grok-3": {
		ID:              "grok-3",
		DisplayName:     "Grok 3",
		Provider:        "xAI",
		ContextWindow:   131_072,
		MaxOutputTokens: 131_072,
		Vision:          true,
		Reasoning:       false,
		PricingInput:    3.00,
		PricingOutput:   15.00,
		KnowledgeCutoff: "2024-11",
		ReleaseDate:     "2025-02",
		Status:          "legacy",
		Notes:           "Superseded by Grok 4 series",
	},
	"grok-3-mini": {
		ID:              "grok-3-mini",
		DisplayName:     "Grok 3 Mini",
		Provider:        "xAI",
		ContextWindow:   131_072,
		MaxOutputTokens: 131_072,
		Vision:          false,
		Reasoning:       true,
		PricingInput:    0.30,
		PricingOutput:   0.50,
		KnowledgeCutoff: "2024-11",
		ReleaseDate:     "2025-02",
		Status:          "legacy",
		Notes:           "Compact reasoning model, superseded by Grok 4.1 Fast",
	},
	// ─── Meta: Current ─────────────────────────────────────────────────
	"llama-4-maverick": {
		ID:              "llama-4-maverick",
		DisplayName:     "Llama 4 Maverick",
		Provider:        "Meta",
		ContextWindow:   512_000,
		MaxOutputTokens: 32_768,
		Vision:          true,
		Reasoning:       false,
		PricingInput:    0.20,
		PricingOutput:   0.60,
		KnowledgeCutoff: "2025-03",
		ReleaseDate:     "2025-04",
		Status:          "current",
		Notes:           "Open-weight MoE, no direct Meta API, access via Together/Fireworks/Groq",
	},
	"llama-4-scout": {
		ID:              "llama-4-scout",
		DisplayName:     "Llama 4 Scout",
		Provider:        "Meta",
		ContextWindow:   10_000_000,
		MaxOutputTokens: 32_768,
		Vision:          true,
		Reasoning:       false,
		PricingInput:    0.15,
		PricingOutput:   0.40,
		KnowledgeCutoff: "2025-03",
		ReleaseDate:     "2025-04",
		Status:          "current",
		Notes:           "Open-weight, 10M context, no direct Meta API, access via third-party providers",
	},
	// ─── Meta: Legacy ──────────────────────────────────────────────────
	"llama-3.3-70b": {
		ID:              "llama-3.3-70b",
		DisplayName:     "Llama 3.3 70B",
		Provider:        "Meta",
		ContextWindow:   128_000,
		MaxOutputTokens: 4_096,
		Vision:          false,
		Reasoning:       false,
		PricingInput:    0.10,
		PricingOutput:   0.30,
		KnowledgeCutoff: "2024-12",
		ReleaseDate:     "2024-12",
		Status:          "legacy",
		Notes:           "Superseded by Llama 4 series, access via third-party providers",
	},
	// ─── Mistral: Current ──────────────────────────────────────────────
	"mistral-large-2512": {
		ID:              "mistral-large-2512",
		DisplayName:     "Mistral Large 3",
		Provider:        "Mistral",
		ContextWindow:   256_000,
		MaxOutputTokens: 8_192,
		Vision:          true,
		Reasoning:       false,
		PricingInput:    0.50,
		PricingOutput:   1.50,
		KnowledgeCutoff: "2025-11",
		ReleaseDate:     "2025-12",
		Status:          "deprecated",
		Notes:           "MoE 675B flagship, strong multilingual, Apache 2.0",
	},
	"ministral-3b-2512": {
		ID:              "ministral-3b-2512",
		DisplayName:     "Ministral 3B",
		Provider:        "Mistral",
		ContextWindow:   256_000,
		MaxOutputTokens: 8_192,
		Vision:          true,
		Reasoning:       false,
		PricingInput:    0.10,
		PricingOutput:   0.10,
		KnowledgeCutoff: "2025-09",
		ReleaseDate:     "2025-12",
		Status:          "deprecated",
		Notes:           "Tiny edge model, 3.4B params + 0.4B vision encoder, open-weight",
	},
	"ministral-8b-2512": {
		ID:              "ministral-8b-2512",
		DisplayName:     "Ministral 8B",
		Provider:        "Mistral",
		ContextWindow:   256_000,
		MaxOutputTokens: 8_192,
		Vision:          true,
		Reasoning:       false,
		PricingInput:    0.10,
		PricingOutput:   0.10,
		KnowledgeCutoff: "2025-09",
		ReleaseDate:     "2025-12",
		Status:          "deprecated",
		Notes:           "Small edge model, 8.4B params + 0.4B vision encoder, open-weight",
	},
	"ministral-14b-2512": {
		ID:              "ministral-14b-2512",
		DisplayName:     "Ministral 14B",
		Provider:        "Mistral",
		ContextWindow:   256_000,
		MaxOutputTokens: 8_192,
		Vision:          true,
		Reasoning:       false,
		PricingInput:    0.10,
		PricingOutput:   0.10,
		KnowledgeCutoff: "2025-09",
		ReleaseDate:     "2025-12",
		Status:          "deprecated",
		Notes:           "Mid-size edge model, 13.5B params + 0.4B vision encoder, open-weight",
	},
	"magistral-small-2509": {
		ID:              "magistral-small-2509",
		DisplayName:     "Magistral Small 1.2",
		Provider:        "Mistral",
		ContextWindow:   128_000,
		MaxOutputTokens: 8_192,
		Vision:          true,
		Reasoning:       true,
		PricingInput:    0.50,
		PricingOutput:   1.50,
		KnowledgeCutoff: "2025-06",
		ReleaseDate:     "2025-09",
		Status:          "deprecated",
		Notes:           "Reasoning model, 24B params, transparent reasoning chains",
	},
	"magistral-medium-2509": {
		ID:              "magistral-medium-2509",
		DisplayName:     "Magistral Medium 1.2",
		Provider:        "Mistral",
		ContextWindow:   128_000,
		MaxOutputTokens: 64_000,
		Vision:          false,
		Reasoning:       true,
		PricingInput:    2.00,
		PricingOutput:   5.00,
		KnowledgeCutoff: "2025-06",
		ReleaseDate:     "2025-09",
		Status:          "deprecated",
		Notes:           "Advanced reasoning model, deep thinking, transparent reasoning chains",
	},
	"mistral-small-2506": {
		ID:              "mistral-small-2506",
		DisplayName:     "Mistral Small 3.2",
		Provider:        "Mistral",
		ContextWindow:   128_000,
		MaxOutputTokens: 8_192,
		Vision:          true,
		Reasoning:       false,
		PricingInput:    0.10,
		PricingOutput:   0.30,
		KnowledgeCutoff: "2025-03",
		ReleaseDate:     "2025-06",
		Status:          "deprecated",
		Notes:           "Fast and cost-efficient, open-weight",
	},
	"devstral-2512": {
		ID:              "devstral-2512",
		DisplayName:     "Devstral 2",
		Provider:        "Mistral",
		ContextWindow:   256_000,
		MaxOutputTokens: 8_192,
		Vision:          false,
		Reasoning:       false,
		PricingInput:    0.40,
		PricingOutput:   2.00,
		KnowledgeCutoff: "2025-11",
		ReleaseDate:     "2025-12",
		Status:          "deprecated",
		Notes:           "Specialized coding agent model, open-weight",
	},
	"mistral-medium-2505": {
		ID:              "mistral-medium-2505",
		DisplayName:     "Mistral Medium 3",
		Provider:        "Mistral",
		ContextWindow:   131_072,
		MaxOutputTokens: 8_192,
		Vision:          true,
		Reasoning:       false,
		PricingInput:    0.40,
		PricingOutput:   2.00,
		KnowledgeCutoff: "2025-03",
		ReleaseDate:     "2025-05",
		Status:          "deprecated",
		Notes:           "Mid-tier Mistral model, good vision support, strong multilingual",
	},
	"devstral-small-2512": {
		ID:              "devstral-small-2512",
		DisplayName:     "Devstral Small 2",
		Provider:        "Mistral",
		ContextWindow:   256_000,
		MaxOutputTokens: 8_192,
		Vision:          false,
		Reasoning:       false,
		PricingInput:    0.40,
		PricingOutput:   2.00,
		KnowledgeCutoff: "2025-11",
		ReleaseDate:     "2025-12",
		Status:          "deprecated",
		Notes:           "24B coding model, runs on consumer GPUs, Apache 2.0, companion to Devstral 2",
	},
	// ─── Mistral: Legacy ───────────────────────────────────────────────
	"codestral-2508": {
		ID:              "codestral-2508",
		DisplayName:     "Codestral",
		Provider:        "Mistral",
		ContextWindow:   128_000,
		MaxOutputTokens: 8_192,
		Vision:          false,
		Reasoning:       false,
		PricingInput:    0.30,
		PricingOutput:   0.90,
		KnowledgeCutoff: "2025-03",
		ReleaseDate:     "2025-08",
		Status:          "deprecated",
		Notes:           "Superseded by Devstral 2",
	},
	// ─── DeepSeek: Current ─────────────────────────────────────────────
	"deepseek-reasoner": {
		ID:              "deepseek-reasoner",
		DisplayName:     "DeepSeek Reasoner",
		Provider:        "DeepSeek",
		ContextWindow:   128_000,
		MaxOutputTokens: 64_000,
		Vision:          false,
		Reasoning:       true,
		PricingInput:    0.28,
		PricingOutput:   0.42,
		KnowledgeCutoff: "2025-09",
		ReleaseDate:     "2025-09",
		Status:          "current",
		Notes:           "DeepSeek-V3.2 Thinking Mode, chain-of-thought reasoning",
	},
	"deepseek-chat": {
		ID:              "deepseek-chat",
		DisplayName:     "DeepSeek Chat",
		Provider:        "DeepSeek",
		ContextWindow:   128_000,
		MaxOutputTokens: 8_000,
		Vision:          false,
		Reasoning:       false,
		PricingInput:    0.28,
		PricingOutput:   0.42,
		KnowledgeCutoff: "2025-09",
		ReleaseDate:     "2025-09",
		Status:          "current",
		Notes:           "DeepSeek-V3.2 Non-thinking Mode, open-weight MoE",
	},
	"deepseek-r1": {
		ID:              "deepseek-r1",
		DisplayName:     "DeepSeek R1",
		Provider:        "DeepSeek",
		ContextWindow:   128_000,
		MaxOutputTokens: 8_000,
		Vision:          false,
		Reasoning:       true,
		PricingInput:    0.55,
		PricingOutput:   2.19,
		KnowledgeCutoff: "2025-01",
		ReleaseDate:     "2025-01",
		Status:          "deprecated",
		Notes:           "Open-weight model name, not official API ID. Use deepseek-reasoner for DeepSeek API. Third-party providers may use deepseek-r1",
	},
	// ─── DeepSeek: Legacy ──────────────────────────────────────────────
	"deepseek-v3": {
		ID:              "deepseek-v3",
		DisplayName:     "DeepSeek V3",
		Provider:        "DeepSeek",
		ContextWindow:   128_000,
		MaxOutputTokens: 16_384,
		Vision:          false,
		Reasoning:       false,
		PricingInput:    0.27,
		PricingOutput:   1.10,
		KnowledgeCutoff: "2025-01",
		ReleaseDate:     "2025-01",
		Status:          "deprecated",
		Notes:           "Merged into deepseek-chat (V3.2), no longer a separate endpoint",
	},
	// ─── Amazon: Current ───────────────────────────────────────────────
	"amazon-nova-micro": {
		ID:              "amazon-nova-micro",
		DisplayName:     "Amazon Nova Micro",
		Provider:        "Amazon",
		ContextWindow:   128_000,
		MaxOutputTokens: 5_000,
		Vision:          false,
		Reasoning:       false,
		PricingInput:    0.035,
		PricingOutput:   0.14,
		KnowledgeCutoff: "2024-10",
		ReleaseDate:     "2024-12",
		Status:          "current",
		Notes:           "Text-only, lowest latency Nova model, via Amazon Bedrock",
	},
	"amazon-nova-lite": {
		ID:              "amazon-nova-lite",
		DisplayName:     "Amazon Nova Lite",
		Provider:        "Amazon",
		ContextWindow:   300_000,
		MaxOutputTokens: 5_000,
		Vision:          true,
		Reasoning:       false,
		PricingInput:    0.06,
		PricingOutput:   0.24,
		KnowledgeCutoff: "2024-10",
		ReleaseDate:     "2024-12",
		Status:          "current",
		Notes:           "Multimodal (text, image, video), fast and low-cost, via Amazon Bedrock",
	},
	"amazon-nova-pro": {
		ID:              "amazon-nova-pro",
		DisplayName:     "Amazon Nova Pro",
		Provider:        "Amazon",
		ContextWindow:   300_000,
		MaxOutputTokens: 5_000,
		Vision:          true,
		Reasoning:       false,
		PricingInput:    0.80,
		PricingOutput:   3.20,
		KnowledgeCutoff: "2024-10",
		ReleaseDate:     "2024-12",
		Status:          "current",
		Notes:           "Multimodal, best balance of accuracy/speed/cost, agentic workflows, via Amazon Bedrock",
	},
	"amazon-nova-premier": {
		ID:              "amazon-nova-premier",
		DisplayName:     "Amazon Nova Premier",
		Provider:        "Amazon",
		ContextWindow:   1_000_000,
		MaxOutputTokens: 5_000,
		Vision:          true,
		Reasoning:       false,
		PricingInput:    2.50,
		PricingOutput:   12.50,
		KnowledgeCutoff: "2024-10",
		ReleaseDate:     "2025-04",
		Status:          "current",
		Notes:           "Most capable Nova 1.0, 1M context, teacher for distillation, via Amazon Bedrock",
	},
	"amazon-nova-2-lite": {
		ID:              "amazon-nova-2-lite",
		DisplayName:     "Amazon Nova 2 Lite",
		Provider:        "Amazon",
		ContextWindow:   1_000_000,
		MaxOutputTokens: 65_536,
		Vision:          true,
		Reasoning:       true,
		PricingInput:    0.30,
		PricingOutput:   2.50,
		KnowledgeCutoff: "2025-09",
		ReleaseDate:     "2025-12",
		Status:          "current",
		Notes:           "Fast reasoning model, extended thinking with budget controls, 1M context, via Amazon Bedrock",
	},
	"amazon-nova-2-pro": {
		ID:              "amazon-nova-2-pro",
		DisplayName:     "Amazon Nova 2 Pro (Preview)",
		Provider:        "Amazon",
		ContextWindow:   1_000_000,
		MaxOutputTokens: 65_536,
		Vision:          true,
		Reasoning:       true,
		PricingInput:    1.25,
		PricingOutput:   10.00,
		KnowledgeCutoff: "2025-09",
		ReleaseDate:     "2025-12",
		Status:          "current",
		Notes:           "Most capable Nova 2, complex agentic tasks, 1M context, preview, via Amazon Bedrock",
	},
	// ─── Cohere: Current ───────────────────────────────────────────────
	"command-a-03-2025": {
		ID:              "command-a-03-2025",
		DisplayName:     "Command A",
		Provider:        "Cohere",
		ContextWindow:   256_000,
		MaxOutputTokens: 8_000,
		Vision:          false,
		Reasoning:       false,
		PricingInput:    2.50,
		PricingOutput:   10.00,
		KnowledgeCutoff: "2025-01",
		ReleaseDate:     "2025-03",
		Status:          "current",
		Notes:           "Cohere flagship, 111B params, excels at RAG/tool use/agents, runs on 2 GPUs",
	},
	"command-a-reasoning-08-2025": {
		ID:              "command-a-reasoning-08-2025",
		DisplayName:     "Command A Reasoning",
		Provider:        "Cohere",
		ContextWindow:   256_000,
		MaxOutputTokens: 32_000,
		Vision:          false,
		Reasoning:       true,
		PricingInput:    2.50,
		PricingOutput:   10.00,
		KnowledgeCutoff: "2025-06",
		ReleaseDate:     "2025-08",
		Status:          "current",
		Notes:           "Reasoning variant of Command A, extended output, enterprise agentic workflows",
	},
	"command-a-vision-07-2025": {
		ID:              "command-a-vision-07-2025",
		DisplayName:     "Command A Vision",
		Provider:        "Cohere",
		ContextWindow:   128_000,
		MaxOutputTokens: 8_000,
		Vision:          true,
		Reasoning:       false,
		PricingInput:    2.50,
		PricingOutput:   10.00,
		KnowledgeCutoff: "2025-05",
		ReleaseDate:     "2025-07",
		Status:          "current",
		Notes:           "Multimodal Command A, 112B params, up to 20 images per request, open weights",
	},
	"command-r7b-12-2024": {
		ID:              "command-r7b-12-2024",
		DisplayName:     "Command R7B",
		Provider:        "Cohere",
		ContextWindow:   128_000,
		MaxOutputTokens: 4_096,
		Vision:          false,
		Reasoning:       false,
		PricingInput:    0.0375,
		PricingOutput:   0.15,
		KnowledgeCutoff: "2024-10",
		ReleaseDate:     "2024-12",
		Status:          "current",
		Notes:           "Smallest R-series, 7B params, fast tool use, 23 languages, runs on consumer GPUs",
	},
	// ─── Perplexity: Current ───────────────────────────────────────────
	"sonar": {
		ID:              "sonar",
		DisplayName:     "Sonar",
		Provider:        "Perplexity",
		ContextWindow:   127_000,
		MaxOutputTokens: 8_000,
		Vision:          false,
		Reasoning:       false,
		PricingInput:    1.00,
		PricingOutput:   1.00,
		KnowledgeCutoff: "2025-02",
		ReleaseDate:     "2025-02",
		Status:          "current",
		Notes:           "Search-augmented LLM, returns answers with citations, cost-effective",
	},
	"sonar-pro": {
		ID:              "sonar-pro",
		DisplayName:     "Sonar Pro",
		Provider:        "Perplexity",
		ContextWindow:   200_000,
		MaxOutputTokens: 8_000,
		Vision:          false,
		Reasoning:       false,
		PricingInput:    3.00,
		PricingOutput:   15.00,
		KnowledgeCutoff: "2025-02",
		ReleaseDate:     "2025-02",
		Status:          "current",
		Notes:           "Advanced search-augmented LLM, 2x citations vs Sonar, 200K context, multi-step queries",
	},
	"sonar-reasoning-pro": {
		ID:              "sonar-reasoning-pro",
		DisplayName:     "Sonar Reasoning Pro",
		Provider:        "Perplexity",
		ContextWindow:   128_000,
		MaxOutputTokens: 8_000,
		Vision:          false,
		Reasoning:       true,
		PricingInput:    2.00,
		PricingOutput:   8.00,
		KnowledgeCutoff: "2025-02",
		ReleaseDate:     "2025-03",
		Status:          "current",
		Notes:           "Reasoning model powered by DeepSeek R1 with CoT, search-augmented",
	},
	"sonar-deep-research": {
		ID:              "sonar-deep-research",
		DisplayName:     "Sonar Deep Research",
		Provider:        "Perplexity",
		ContextWindow:   128_000,
		MaxOutputTokens: 8_000,
		Vision:          false,
		Reasoning:       true,
		PricingInput:    2.00,
		PricingOutput:   8.00,
		KnowledgeCutoff: "2025-02",
		ReleaseDate:     "2025-10",
		Status:          "current",
		Notes:           "Multi-step deep research, automated web search and analysis, comprehensive reports with citations",
	},
	// ─── AI21: Current ─────────────────────────────────────────────────
	"jamba-large-1.7": {
		ID:              "jamba-large-1.7",
		DisplayName:     "Jamba Large 1.7",
		Provider:        "AI21",
		ContextWindow:   256_000,
		MaxOutputTokens: 4_096,
		Vision:          false,
		Reasoning:       false,
		PricingInput:    2.00,
		PricingOutput:   8.00,
		KnowledgeCutoff: "2025-06",
		ReleaseDate:     "2025-08",
		Status:          "current",
		Notes:           "SSM-Transformer hybrid, 256K context, enterprise-focused, available via AI21 API and Bedrock",
	},
	"jamba-mini-1.7": {
		ID:              "jamba-mini-1.7",
		DisplayName:     "Jamba Mini 1.7",
		Provider:        "AI21",
		ContextWindow:   256_000,
		MaxOutputTokens: 4_096,
		Vision:          false,
		Reasoning:       false,
		PricingInput:    0.20,
		PricingOutput:   0.40,
		KnowledgeCutoff: "2025-06",
		ReleaseDate:     "2025-07",
		Status:          "current",
		Notes:           "Compact SSM-Transformer hybrid, 12B active params, 256K context, cost-efficient",
	},
	// ─── Moonshot (Kimi): Current ─────────────────────────────────────
	"kimi-k2.5": {
		ID:              "kimi-k2.5",
		DisplayName:     "Kimi K2.5",
		Provider:        "Moonshot",
		ContextWindow:   262_144,
		MaxOutputTokens: 16_384,
		Vision:          true,
		Reasoning:       true,
		PricingInput:    0.60,
		PricingOutput:   3.00,
		KnowledgeCutoff: "2024-12",
		ReleaseDate:     "2026-01",
		Status:          "current",
		Notes:           "Open-source native multimodal, 1T params (32B active) MoE, agent swarm capability. API: api.moonshot.ai/v1",
	},
	"kimi-k2-thinking": {
		ID:              "kimi-k2-thinking",
		DisplayName:     "Kimi K2 Thinking",
		Provider:        "Moonshot",
		ContextWindow:   256_000,
		MaxOutputTokens: 96_000,
		Vision:          false,
		Reasoning:       true,
		PricingInput:    0.60,
		PricingOutput:   2.50,
		KnowledgeCutoff: "2024-12",
		ReleaseDate:     "2025-12",
		Status:          "current",
		Notes:           "Reasoning model with explicit thinking traces (reasoning_content), 1T MoE. API: api.moonshot.ai/v1",
	},
	"kimi-k2-0905-preview": {
		ID:              "kimi-k2-0905-preview",
		DisplayName:     "Kimi K2 (0905)",
		Provider:        "Moonshot",
		ContextWindow:   256_000,
		MaxOutputTokens: 16_384,
		Vision:          false,
		Reasoning:       true,
		PricingInput:    0.60,
		PricingOutput:   2.50,
		KnowledgeCutoff: "2024-12",
		ReleaseDate:     "2025-09",
		Status:          "current",
		Notes:           "Strong coding and agentic tasks, 1T MoE (32B active), 256K context. API: api.moonshot.ai/v1",
	},
	// ─── Zhipu (GLM): Current ─────────────────────────────────────────
	"glm-5": {
		ID:              "glm-5",
		DisplayName:     "GLM-5",
		Provider:        "Zhipu",
		ContextWindow:   200_000,
		MaxOutputTokens: 128_000,
		Vision:          true,
		Reasoning:       true,
		PricingInput:    1.00,
		PricingOutput:   3.20,
		KnowledgeCutoff: "2024-09",
		ReleaseDate:     "2026-02",
		Status:          "current",
		Notes:           "Zhipu flagship, 744B MoE (40B active), native multimodal (image/audio/video), interleaved thinking. API: open.bigmodel.cn. Also: z.ai, zhipuai",
	},
	"glm-4.7": {
		ID:              "glm-4.7",
		DisplayName:     "GLM-4.7",
		Provider:        "Zhipu",
		ContextWindow:   200_000,
		MaxOutputTokens: 128_000,
		Vision:          false,
		Reasoning:       true,
		PricingInput:    0.60,
		PricingOutput:   2.20,
		KnowledgeCutoff: "2024-09",
		ReleaseDate:     "2026-01",
		Status:          "current",
		Notes:           "Latest Zhipu AI flagship, interleaved thinking, 200K context. API: open.bigmodel.cn. Also: z.ai, zhipuai",
	},
	"glm-4.7-flashx": {
		ID:              "glm-4.7-flashx",
		DisplayName:     "GLM-4.7 FlashX",
		Provider:        "Zhipu",
		ContextWindow:   200_000,
		MaxOutputTokens: 128_000,
		Vision:          false,
		Reasoning:       true,
		PricingInput:    0.07,
		PricingOutput:   0.40,
		KnowledgeCutoff: "2024-09",
		ReleaseDate:     "2026-01",
		Status:          "current",
		Notes:           "Fast 30B dense model, cost-efficient reasoning. API: open.bigmodel.cn. Also: z.ai, zhipuai",
	},
	"glm-4.6v": {
		ID:              "glm-4.6v",
		DisplayName:     "GLM-4.6V",
		Provider:        "Zhipu",
		ContextWindow:   128_000,
		MaxOutputTokens: 8_000,
		Vision:          true,
		Reasoning:       false,
		PricingInput:    0.30,
		PricingOutput:   0.90,
		KnowledgeCutoff: "2024-09",
		ReleaseDate:     "2025-12",
		Status:          "deprecated",
		Notes:           "Vision model, images/videos/documents, native function calling. API: open.bigmodel.cn. Also: z.ai, zhipuai",
	},
	// ─── NVIDIA: Current ──────────────────────────────────────────────
	"nvidia/nemotron-3-nano-30b-a3b": {
		ID:              "nvidia/nemotron-3-nano-30b-a3b",
		DisplayName:     "Nemotron 3 Nano 30B",
		Provider:        "NVIDIA",
		ContextWindow:   1_000_000,
		MaxOutputTokens: 32_768,
		Vision:          false,
		Reasoning:       true,
		PricingInput:    0.06,
		PricingOutput:   0.24,
		KnowledgeCutoff: "2025-06",
		ReleaseDate:     "2025-12",
		Status:          "current",
		Notes:           "Hybrid Mamba-2+Transformer MoE, 30B total 3.5B active, 1M context, configurable thinking. Pricing via OpenRouter, free on build.nvidia.com. NVIDIA NIM platform",
	},
	"nvidia/llama-3.1-nemotron-ultra-253b-v1": {
		ID:              "nvidia/llama-3.1-nemotron-ultra-253b-v1",
		DisplayName:     "Nemotron Ultra 253B",
		Provider:        "NVIDIA",
		ContextWindow:   131_072,
		MaxOutputTokens: 16_384,
		Vision:          false,
		Reasoning:       true,
		PricingInput:    0.60,
		PricingOutput:   1.80,
		KnowledgeCutoff: "2023-12",
		ReleaseDate:     "2025-04",
		Status:          "current",
		Notes:           "Flagship 253B via NAS from Llama 3.1 405B, reasoning ON/OFF modes. Pricing via OpenRouter, free on build.nvidia.com. NVIDIA NIM platform",
	},
	// ─── Tencent (Hunyuan): Current ───────────────────────────────────
	"hunyuan-turbos": {
		ID:              "hunyuan-turbos",
		DisplayName:     "Hunyuan TurboS",
		Provider:        "Tencent",
		ContextWindow:   256_000,
		MaxOutputTokens: 4_096,
		Vision:          false,
		Reasoning:       true,
		PricingInput:    0.11,
		PricingOutput:   0.28,
		KnowledgeCutoff: "2024-12",
		ReleaseDate:     "2025-02",
		Status:          "current",
		Notes:           "Hybrid Mamba-Transformer MoE, adaptive chain-of-thought reasoning, fast. Via Tencent Cloud API",
	},
	"hunyuan-t1": {
		ID:              "hunyuan-t1",
		DisplayName:     "Hunyuan T1",
		Provider:        "Tencent",
		ContextWindow:   256_000,
		MaxOutputTokens: 16_000,
		Vision:          false,
		Reasoning:       true,
		PricingInput:    0.14,
		PricingOutput:   0.56,
		KnowledgeCutoff: "2024-12",
		ReleaseDate:     "2025-03",
		Status:          "current",
		Notes:           "Deep reasoning model, MoE with 52B active params, 256K context. Via Tencent Cloud API",
	},
	"hunyuan-a13b": {
		ID:              "hunyuan-a13b",
		DisplayName:     "Hunyuan A13B",
		Provider:        "Tencent",
		ContextWindow:   256_000,
		MaxOutputTokens: 4_096,
		Vision:          false,
		Reasoning:       true,
		PricingInput:    0.07,
		PricingOutput:   0.28,
		KnowledgeCutoff: "2024-12",
		ReleaseDate:     "2025-06",
		Status:          "current",
		Notes:           "MoE 80B total, 13B active, dual-mode reasoning, cost-efficient. Via Tencent Cloud API",
	},
	// ─── Microsoft (Phi): Current ─────────────────────────────────────
	"phi-4": {
		ID:              "phi-4",
		DisplayName:     "Phi-4",
		Provider:        "Microsoft",
		ContextWindow:   16_384,
		MaxOutputTokens: 16_384,
		Vision:          false,
		Reasoning:       true,
		PricingInput:    0.13,
		PricingOutput:   0.50,
		KnowledgeCutoff: "2024-06",
		ReleaseDate:     "2024-12",
		Status:          "current",
		Notes:           "14B SLM, strong reasoning. Open weights, available via Azure and third-party providers. OpenRouter: microsoft/phi-4",
	},
	"phi-4-multimodal-instruct": {
		ID:              "phi-4-multimodal-instruct",
		DisplayName:     "Phi-4 Multimodal",
		Provider:        "Microsoft",
		ContextWindow:   131_072,
		MaxOutputTokens: 4_000,
		Vision:          true,
		Reasoning:       true,
		PricingInput:    0.08,
		PricingOutput:   0.32,
		KnowledgeCutoff: "2024-06",
		ReleaseDate:     "2025-02",
		Status:          "current",
		Notes:           "5.6B multimodal (vision+audio), 128K context, MIT license. Azure: Phi-4-multimodal-instruct",
	},
	"phi-4-reasoning-plus": {
		ID:              "phi-4-reasoning-plus",
		DisplayName:     "Phi-4 Reasoning Plus",
		Provider:        "Microsoft",
		ContextWindow:   32_768,
		MaxOutputTokens: 32_768,
		Vision:          false,
		Reasoning:       true,
		PricingInput:    0.06,
		PricingOutput:   0.14,
		KnowledgeCutoff: "2024-06",
		ReleaseDate:     "2025-05",
		Status:          "current",
		Notes:           "14B enhanced reasoning with RL, 50% more reasoning tokens vs Phi-4. Azure: Phi-4-reasoning-plus",
	},
	// ─── MiniMax: Current ─────────────────────────────────────────────
	"minimax-m2.1": {
		ID:              "minimax-m2.1",
		DisplayName:     "MiniMax M2.1",
		Provider:        "MiniMax",
		ContextWindow:   200_000,
		MaxOutputTokens: 128_000,
		Vision:          false,
		Reasoning:       true,
		PricingInput:    0.30,
		PricingOutput:   1.20,
		KnowledgeCutoff: "2024-12",
		ReleaseDate:     "2025-12",
		Status:          "current",
		Notes:           "Latest MiniMax, MoE (230B/10B active), interleaved thinking, optimized for coding and agents. Official ID: MiniMax-M2.1",
	},
	"minimax-01": {
		ID:              "minimax-01",
		DisplayName:     "MiniMax-01",
		Provider:        "MiniMax",
		ContextWindow:   4_000_000,
		MaxOutputTokens: 128_000,
		Vision:          true,
		Reasoning:       true,
		PricingInput:    0.20,
		PricingOutput:   1.10,
		KnowledgeCutoff: "2024-12",
		ReleaseDate:     "2025-01",
		Status:          "deprecated",
		Notes:           "4M context via Lightning Attention, 456B/45.9B active, includes vision (MiniMax-VL-01)",
	},
	// ─── Xiaomi (MiMo): Current ───────────────────────────────────────
	"mimo-v2-flash": {
		ID:              "mimo-v2-flash",
		DisplayName:     "MiMo V2 Flash",
		Provider:        "Xiaomi",
		ContextWindow:   262_144,
		MaxOutputTokens: 8_192,
		Vision:          false,
		Reasoning:       true,
		PricingInput:    0.10,
		PricingOutput:   0.30,
		KnowledgeCutoff: "2024-12",
		ReleaseDate:     "2025-10",
		Status:          "current",
		Notes:           "309B MoE (15B active), MIT license, controllable reasoning mode. API: platform.xiaomimimo.com",
	},
	// ─── Kuaishou (KwaiKAT): Current ──────────────────────────────────
	"kat-coder-pro": {
		ID:              "kat-coder-pro",
		DisplayName:     "KAT-Coder Pro",
		Provider:        "Kuaishou",
		ContextWindow:   256_000,
		MaxOutputTokens: 128_000,
		Vision:          false,
		Reasoning:       true,
		PricingInput:    0.21,
		PricingOutput:   0.83,
		KnowledgeCutoff: "2024-12",
		ReleaseDate:     "2025-10",
		Status:          "current",
		Notes:           "Coding specialist, SWE-Bench 73.4%, ~72B active MoE. Kuaishou/Kwai model. Also: kwaipilot/kat-coder-pro on OpenRouter",
	},
}
